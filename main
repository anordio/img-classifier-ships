from google.colab import files
from google.colab import drive
import zipfile

#### MOUNT of my GOOGLE DRIVE FOLDER

drive.mount('/content/gdrive')

zf = zipfile.ZipFile('/content/gdrive/My Drive/Games of Deep Learning/resized_all_images.zip') ### IMAGES RESIZED
zf.extractall()

!pip install efficientnet
!pip install keras-adabound
import io
import pandas as pd
import numpy as np
import tensorflow as tf
from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator
import zipfile
import matplotlib.pyplot as plt 
import numpy as np
import os
from sklearn.metrics import f1_score, precision_score, recall_score
from sklearn.model_selection import StratifiedKFold

from keras.utils.data_utils import Sequence
from keras.models import Sequential, Model
from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, BatchNormalization, GlobalAveragePooling2D, SpatialDropout2D,GlobalMaxPooling2D
from keras import backend as K
from keras.callbacks import Callback
from efficientnet import EfficientNetB3
from keras_adabound import AdaBound


!ls -al


df_train = pd.read_csv('/content/gdrive/My Drive/Games of Deep Learning/train.csv')
print('Cargo: '+str(sum(df_train['category']==1)) + ' samples')
print('Military: '+str(sum(df_train['category']==2)) + ' samples')
print('Carrier: '+str(sum(df_train['category']==3)) + ' samples')
print('Cruise: '+str(sum(df_train['category']==4)) + ' samples')
print('Tankers: '+str(sum(df_train['category']==5)) + ' samples')


df_train.loc[df_train['category']==1,'category'] = 'Cargo'
df_train.loc[df_train['category']==2,'category'] = 'Military'
df_train.loc[df_train['category']==3,'category'] = 'Carrier'
df_train.loc[df_train['category']==4,'category'] = 'Cruise'
df_train.loc[df_train['category']==5,'category'] = 'Tankers'
df_train['category'] = df_train['category'].astype(str)

train_datagen = ImageDataGenerator(rescale=1./255.,width_shift_range=0.1, height_shift_range=0.1,fill_mode='nearest',
                             brightness_range=[0.8,1.25],shear_range=0.01, zoom_range=[0.9, 1.25],horizontal_flip=True,dtype='float32',
                                  rotation_range=45)


val_test_datagen = ImageDataGenerator(rescale=1./255.,dtype='float32')


folds = StratifiedKFold(n_splits=5, shuffle=True, random_state = 45)



def f1_loss(y_true, y_pred): ### LOSS based on a differntiable F1-weighted score    
    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)
    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)
    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)
    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)


    p = tp / (tp + fp + K.epsilon())
    r = tp / (tp + fn + K.epsilon())
    

    f1 = 2*p*r / (p+r+K.epsilon())
    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)
    return 1 - K.mean(f1)
  

class CustomMetrics2(Callback): ## Callback function to evaluate weighted F1 each epoch & see performances

    def __init__(self, validation_generator, validation_steps):
        self.validation_generator = validation_generator
        self.validation_steps = validation_steps
        self.val_f1 = []
        self.val_precision = []
        self.val_recall = []


    def on_epoch_end(self, batch, logs={}):
        self.scores = {
            'val_y_true': [],
            'val_y_pred': [],
        }
        y_true_list = list()
        y_pred_list = list()
        for batch_index in range(self.validation_steps):
            features, y_true = next(self.validation_generator) 
            y_true = y_true.astype(int)
            y_pred = np.asarray(self.model.predict(features))
            y_pred = list(y_pred.argmax(axis=1).astype(int) + 1)
            y_true = list(y_true.argmax(axis=1).astype(int) + 1)
            y_true_list += y_true
            y_pred_list += y_pred
        
        y_pred_list = np.asarray(y_pred_list)
        y_true_list = np.asarray(y_true_list)
        
        f1 = f1_score(y_true_list,y_pred_list,average='weighted')
        p = precision_score(y_true_list,y_pred_list,average='weighted')
        r = recall_score(y_true_list,y_pred_list,average='weighted')
        self.val_f1.append(f1)
        self.val_precision.append(p)
        self.val_recall.append(r)
        
        print('— val_f1: %f — val_precision: %f — val_recall %f' % (f1, p, r))
        
        dict_str = {'Cargo': 1, 'Carrier': 2, 'Cruise': 3, 'Military': 4, 'Tankers': 5}
        
        print('True Cargo: '+ str(sum(y_true_list==1)) + ' True Carrier: '+ str(sum(y_true_list==2)) + ' True Cruise: ' + str(sum(y_true_list==3)) + 
              ' True Military: ' + str(sum(y_true_list==4)) + ' True Tankers: '+ str(sum(y_true_list==5)))
        
        print('Cargo not predicted: ' + str(sum((y_true_list==1) & (y_pred_list!=1))))
        print('Carrier not predicted: ' + str(sum((y_true_list==2) & (y_pred_list!=2))))
        print('Cruise not predicted: ' + str(sum((y_true_list==3) & (y_pred_list!=3))))
        print('Military not predicted: ' + str(sum((y_true_list==4) & (y_pred_list!=4))))
        print('Tankers not predicted: ' + str(sum((y_true_list==5) & (y_pred_list!=5))))
        return f1, p, r


def build_model(base_model): 
  x = base_model.output # EfficientNetB3
  
  x = GlobalAveragePooling2D()(x)
  x = Dropout(rate=0.3)(x)
  
  x = Dense(5,activation='softmax')(x) #final layer with softmax activation
  return x


def plot_results(history,valid_metrics): ## Plot of loss/f1
  print(history.history.keys())
    # "Loss"
  plt.figure()
  plt.plot(history.history['loss'])
  plt.plot(history.history['val_loss'])
  plt.title('model loss')
  plt.ylabel('loss')
  plt.xlabel('epoch')
  plt.legend(['train', 'validation'], loc='upper left')
  plt.show()

  plt.figure()
  # categorical_accuracy
  plt.plot(valid_metrics.val_f1)
  plt.title('VAL F1')
  plt.ylabel('F1')
  plt.xlabel('epoch')
  plt.legend(['validation'], loc='upper left')
  plt.show()
  

#### ITERATIONS on K-FOLDS


def fit_fold(train,validation): # Function to use a KFold
  
  baseline_model = EfficientNetB3(weights='imagenet',include_top=False,input_shape=(210,140,3),classes=5)
  model=Model(inputs=baseline_model.input,outputs=build_model(baseline_model)) 
  
  for layer in model.layers:
    layer.trainable=True
  
  opt = AdaBound(lr=1e-03,final_lr=0.1,gamma=1e-03,weight_decay=0.)
  model.compile(loss=f1_loss,optimizer=opt,metrics=['categorical_accuracy']) 

  train_generator=train_datagen.flow_from_dataframe(dataframe=train, directory="./resized_all_images/",x_col="image",y_col="category",
                                                    classes= ['Cargo','Military','Carrier','Cruise','Tankers'], batch_size=32,shuffle=True,
                                                    class_mode="categorical", target_size=(210,140))  

  validation_generator=val_test_datagen.flow_from_dataframe(dataframe=validation, directory="./resized_all_images/",x_col="image",y_col="category",
                                                    classes= ['Cargo','Military','Carrier','Cruise','Tankers'], 
                                                    batch_size=32,shuffle=True,class_mode="categorical", target_size=(210,140))
  
  filepath = 'weights.{epoch:02d}-{val_loss:.2f}.hdf5'
  STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size
  STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size
  
  valid_metrics = CustomMetrics2(validation_generator,STEP_SIZE_VALID)
  
  history = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN, validation_data=validation_generator, 
                                validation_steps=STEP_SIZE_VALID, epochs=80,verbose=1, callbacks=[valid_metrics])
  plot_results(history,valid_metrics) #Plot loss functions & F1-score for validation set for each Fold
  
  return history, model, valid_metrics 


cont = 0

Kfolds = folds.split(df_train.image, df_train.category)            
            
for train_index, test_index in folds.split(df_train.image, df_train.category):
  cont +=1
  print('---- FOLD '+str(cont)+' ----')
  print('TRAIN')
  print(sum(df_train.loc[train_index,'category']=='Cargo'))
  print(sum(df_train.loc[train_index,'category']=='Military'))
  print(sum(df_train.loc[train_index,'category']=='Carrier'))
  print(sum(df_train.loc[train_index,'category']=='Cruise'))
  print(sum(df_train.loc[train_index,'category']=='Tankers'))
  print('TEST')
  print(sum(df_train.loc[test_index,'category']=='Cargo'))
  print(sum(df_train.loc[test_index,'category']=='Military'))
  print(sum(df_train.loc[test_index,'category']=='Carrier'))
  print(sum(df_train.loc[test_index,'category']=='Cruise'))
  print(sum(df_train.loc[test_index,'category']=='Tankers'))
  X_train, X_test = df_train.image[train_index], df_train.image[test_index]
  y_train, y_test = df_train.category[train_index], df_train.category[test_index]
  tmp_train = pd.DataFrame({'image':X_train,'category':y_train})
  tmp_test = pd.DataFrame({'image':X_test,'category':y_test})
  history, model, valid_metrics = fit_fold(tmp_train,tmp_test)
  
  
  def fit_final_model(train): # Function to use the whole train dataset for my final model 
  
  baseline_model = EfficientNetB3(weights='imagenet',include_top=False,input_shape=(210,140,3),classes=5)
  model=Model(inputs=baseline_model.input,outputs=build_model(baseline_model)) 
  for layer in model.layers:
    layer.trainable=True
  
  opt = AdaBound(lr=1e-03,final_lr=0.1,gamma=1e-03,weight_decay=0.)
  model.compile(loss=f1_loss,optimizer=opt,metrics=['categorical_accuracy'])  

  train_generator=train_datagen.flow_from_dataframe(dataframe=train,directory="./resized_all_images/",x_col="image",y_col="category",
                                            classes= ['Cargo','Military','Carrier','Cruise','Tankers'], batch_size=32,shuffle=True,class_mode="categorical", target_size=(210,140))
   

  STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size
  history = tpu_model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN, epochs=80,verbose=1)
  
  return history, model

history,final_model = fit_final_model(df_train)


### TEST DATASET

import csv

df_test = pd.read_csv('/content/gdrive/My Drive/Games of Deep Learning/test_ApKoW4T.csv')

generatore = ImageDataGenerator(rescale=1./255)
test_generator = generatore.flow_from_dataframe(dataframe=df_test,directory="./resized_all_images/",x_col="image",
                                            batch_size=1,shuffle=False,class_mode=None, target_size=(210,140))

L=len(df_test)

test_predict = final_model.predict_generator(test_generator,steps = L).argmax(axis=1)

### Mapping
{'Cargo': 0, 'Carrier': 1, 'Cruise': 2, 'Military': 3, 'Tankers': 4}
{'Cargo': 1, 'Military': 2, 'Carrier': 3, 'Cruise': 4, 'Tankers': 5}
dict2 ={0:1,1:3,2:4,3:2,4:5}
for n in range(0,L):
  test_predict[n] = dict2[test_predict[n]]

           
with open('test_results.csv',mode='w') as csv_file:
  csv_writer = csv.writer(csv_file, delimiter=',')
  csv_writer.writerow(['image','category'])
  for k in range(0,L):
    csv_writer.writerow([df_test.loc[k,'image'],int(test_predict[k])])
files.download('/content/test_results.csv')
